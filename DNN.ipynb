{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## убрать строки с нулевыми значениями Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "import time\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rmspe(y,y_pred):\n",
    "    summ = 0\n",
    "    for i in range(len(y)):\n",
    "        if y.iloc[i] != 0:\n",
    "            summ += (1-y_pred[i]/y.iloc[i])**2\n",
    "    return sqrt(summ/len(y))\n",
    "\n",
    "def substract_cols(df):\n",
    "    df['CompetitionOpen'] = 12 * (df.Year - df['CompetitionOpenSinceYear']) + (df.Month - df['CompetitionOpenSinceMonth'])\n",
    "    df['CompetitionOpen'] = df.CompetitionOpen.apply(lambda x: x if x > 0 else 0)\n",
    "    df.loc[df['CompetitionOpenSinceYear'] < 0, 'CompetitionOpen'] = 0\n",
    "    df['PromoOpen'] = 12 * (df.Year - df.Promo2SinceYear) + (df['WeekOfYear'] - df['Promo2SinceWeek']) / 4.0\n",
    "    df['PromoOpen'] = df.PromoOpen.apply(lambda x: x if x > 0 else 0)\n",
    "    df.loc[df['Promo2SinceYear'] == 0, 'PromoOpen'] = 0\n",
    "    df.loc[df['Promo2SinceYear'] < 0, 'PromoOpen'] = 0\n",
    "    df.drop(['CompetitionOpenSinceYear',\n",
    "             'CompetitionOpenSinceMonth',\n",
    "             'Promo2SinceYear',\n",
    "             'Promo2SinceWeek'], axis=1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2698: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('data/train_v2.csv')\n",
    "df_train['Date']  = pd.to_datetime(df_train['Date'], errors='coerce')\n",
    "df_train['Year'] = df_train['Date'].dt.year\n",
    "df_train['Month'] = df_train['Date'].dt.month\n",
    "df_train['WeekOfYear'] = df_train['Date'].dt.weekofyear\n",
    "df_train['Day'] = df_train['Date'].dt.day\n",
    "df_train = df_train.drop('Date', axis=1)\n",
    "\n",
    "df_test = pd.read_csv('data/test_v2.csv')\n",
    "df_test['Date']  = pd.to_datetime(df_test['Date'], errors='coerce')\n",
    "df_test['Year'] = df_test['Date'].dt.year\n",
    "df_test['Month'] = df_test['Date'].dt.month\n",
    "df_test['WeekOfYear'] = df_test['Date'].dt.weekofyear\n",
    "df_test['Day'] = df_test['Date'].dt.day\n",
    "df_test = df_test.drop('Date', axis=1)\n",
    "\n",
    "df_store = pd.read_csv('data/store.csv')\n",
    "df_store = df_store.fillna(-1)\n",
    "\n",
    "df_train = df_train[df_train.Sales > 0]\n",
    "df_train = df_train[df_train.Customers > 0]\n",
    "\n",
    "df_train_store = df_train.join(df_store.set_index('Store'), on='Store')\n",
    "df_train_store = substract_cols(df_train_store)\n",
    "df_train_store.drop(['Open','PromoInterval','Year','Month','WeekOfYear'], axis=1, inplace=True)\n",
    "\n",
    "df_test_store = df_test.join(df_store.set_index('Store'), on='Store')\n",
    "df_test_store = substract_cols(df_test_store)\n",
    "df_test_store.drop(['Open','PromoInterval','Year','Month','WeekOfYear'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "df = df_train_store\n",
    "labels = df['Sales']\n",
    "df.drop(['Sales'], axis=1, inplace=True)\n",
    "df_train_store_with_out_sales = df\n",
    "frames = [df_train_store_with_out_sales, df_test_store]\n",
    "super_df = pd.concat(frames)\n",
    "\n",
    "mappings = {'0':0, 'a':1, 'b':2, 'c':3, 'd':4}\n",
    "super_df.StateHoliday.replace(mappings, inplace=True)\n",
    "super_df.StoreType.replace(mappings, inplace=True)\n",
    "super_df.Assortment.replace(mappings, inplace=True)\n",
    "\n",
    "# scaler = MinMaxScaler() \n",
    "# scaled_values = scaler.fit_transform(super_df) \n",
    "# super_df.iloc[:,2] = scaled_values[:,2]\n",
    "# super_df.iloc[:,11:14] = scaled_values[:,11:14]\n",
    "\n",
    "super_df = pd.get_dummies(super_df, columns=['Store', \n",
    "                                                         'DayOfWeek',\n",
    "                                                         'StateHoliday',\n",
    "                                                         'Day',\n",
    "                                                         'StoreType',\n",
    "                                                         'Assortment'])\n",
    "\n",
    "start_ind = df_train_store.shape[0]\n",
    "df_train_store = super_df.iloc[:start_ind,:]\n",
    "df_test_store = super_df.iloc[start_ind:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customers</th>\n",
       "      <th>Promo</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "      <th>CompetitionDistance</th>\n",
       "      <th>Promo2</th>\n",
       "      <th>CompetitionOpen</th>\n",
       "      <th>PromoOpen</th>\n",
       "      <th>Store_1</th>\n",
       "      <th>Store_2</th>\n",
       "      <th>Store_3</th>\n",
       "      <th>...</th>\n",
       "      <th>Day_29</th>\n",
       "      <th>Day_30</th>\n",
       "      <th>Day_31</th>\n",
       "      <th>StoreType_1</th>\n",
       "      <th>StoreType_2</th>\n",
       "      <th>StoreType_3</th>\n",
       "      <th>StoreType_4</th>\n",
       "      <th>Assortment_1</th>\n",
       "      <th>Assortment_2</th>\n",
       "      <th>Assortment_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>616</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1270.0</td>\n",
       "      <td>0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>624</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>570.0</td>\n",
       "      <td>1</td>\n",
       "      <td>86.0</td>\n",
       "      <td>58.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>678</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14130.0</td>\n",
       "      <td>1</td>\n",
       "      <td>97.0</td>\n",
       "      <td>45.75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1632</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>620.0</td>\n",
       "      <td>0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>617</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>29910.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1170 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Customers  Promo  SchoolHoliday  CompetitionDistance  Promo2  \\\n",
       "0        616      1              0               1270.0       0   \n",
       "1        624      1              0                570.0       1   \n",
       "2        678      1              0              14130.0       1   \n",
       "3       1632      1              0                620.0       0   \n",
       "4        617      1              0              29910.0       0   \n",
       "\n",
       "   CompetitionOpen  PromoOpen  Store_1  Store_2  Store_3      ...       \\\n",
       "0             76.0       0.00        1        0        0      ...        \n",
       "1             86.0      58.00        0        1        0      ...        \n",
       "2             97.0      45.75        0        0        1      ...        \n",
       "3             64.0       0.00        0        0        0      ...        \n",
       "4              0.0       0.00        0        0        0      ...        \n",
       "\n",
       "   Day_29  Day_30  Day_31  StoreType_1  StoreType_2  StoreType_3  StoreType_4  \\\n",
       "0       0       1       0            0            0            1            0   \n",
       "1       0       1       0            1            0            0            0   \n",
       "2       0       1       0            1            0            0            0   \n",
       "3       0       1       0            0            0            1            0   \n",
       "4       0       1       0            1            0            0            0   \n",
       "\n",
       "   Assortment_1  Assortment_2  Assortment_3  \n",
       "0             1             0             0  \n",
       "1             1             0             0  \n",
       "2             1             0             0  \n",
       "3             0             0             1  \n",
       "4             1             0             0  \n",
       "\n",
       "[5 rows x 1170 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "super_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customers</th>\n",
       "      <th>Promo</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "      <th>CompetitionDistance</th>\n",
       "      <th>Promo2</th>\n",
       "      <th>CompetitionOpen</th>\n",
       "      <th>PromoOpen</th>\n",
       "      <th>Store_1</th>\n",
       "      <th>Store_2</th>\n",
       "      <th>Store_3</th>\n",
       "      <th>...</th>\n",
       "      <th>Day_29</th>\n",
       "      <th>Day_30</th>\n",
       "      <th>Day_31</th>\n",
       "      <th>StoreType_1</th>\n",
       "      <th>StoreType_2</th>\n",
       "      <th>StoreType_3</th>\n",
       "      <th>StoreType_4</th>\n",
       "      <th>Assortment_1</th>\n",
       "      <th>Assortment_2</th>\n",
       "      <th>Assortment_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>555</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1270.0</td>\n",
       "      <td>0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>570.0</td>\n",
       "      <td>1</td>\n",
       "      <td>92.0</td>\n",
       "      <td>64.50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>821</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14130.0</td>\n",
       "      <td>1</td>\n",
       "      <td>103.0</td>\n",
       "      <td>52.25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1498</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>620.0</td>\n",
       "      <td>0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>559</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29910.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1170 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Customers  Promo  SchoolHoliday  CompetitionDistance  Promo2  \\\n",
       "0        555      1              1               1270.0       0   \n",
       "1        625      1              1                570.0       1   \n",
       "2        821      1              1              14130.0       1   \n",
       "3       1498      1              1                620.0       0   \n",
       "4        559      1              1              29910.0       0   \n",
       "\n",
       "   CompetitionOpen  PromoOpen  Store_1  Store_2  Store_3      ...       \\\n",
       "0             82.0       0.00        1        0        0      ...        \n",
       "1             92.0      64.50        0        1        0      ...        \n",
       "2            103.0      52.25        0        0        1      ...        \n",
       "3             70.0       0.00        0        0        0      ...        \n",
       "4              3.0       0.00        0        0        0      ...        \n",
       "\n",
       "   Day_29  Day_30  Day_31  StoreType_1  StoreType_2  StoreType_3  StoreType_4  \\\n",
       "0       0       0       1            0            0            1            0   \n",
       "1       0       0       1            1            0            0            0   \n",
       "2       0       0       1            1            0            0            0   \n",
       "3       0       0       1            0            0            1            0   \n",
       "4       0       0       1            1            0            0            0   \n",
       "\n",
       "   Assortment_1  Assortment_2  Assortment_3  \n",
       "0             1             0             0  \n",
       "1             1             0             0  \n",
       "2             1             0             0  \n",
       "3             0             0             1  \n",
       "4             1             0             0  \n",
       "\n",
       "[5 rows x 1170 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_store.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2010: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X = df_train_store.values\n",
    "y = labels.values\n",
    "\n",
    "X_test = df_test_store.values\n",
    "\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X, y, train_size=0.85, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=1170, kernel_initializer=\"normal\", activation=\"relu\", units=1100)`\n",
      "  if __name__ == '__main__':\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(kernel_initializer=\"normal\", units=1)`\n",
      "  if sys.path[0] == '':\n",
      "/anaconda3/lib/python3.6/site-packages/keras/models.py:848: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54688 samples, validate on 8204 samples\n",
      "Epoch 1/100\n",
      "54688/54688 [==============================] - 10s - loss: 52188875.1738 - val_loss: 40668787.0502\n",
      "Epoch 2/100\n",
      "54688/54688 [==============================] - 11s - loss: 33217952.6466 - val_loss: 23778441.4130\n",
      "Epoch 3/100\n",
      "54688/54688 [==============================] - 10s - loss: 16436600.3508 - val_loss: 9113405.2277\n",
      "Epoch 4/100\n",
      "54688/54688 [==============================] - 10s - loss: 5959925.9579 - val_loss: 3822774.9032\n",
      "Epoch 5/100\n",
      "54688/54688 [==============================] - 10s - loss: 3803725.8726 - val_loss: 3417710.0334\n",
      "Epoch 6/100\n",
      "54688/54688 [==============================] - 10s - loss: 3652212.1728 - val_loss: 3321331.3784\n",
      "Epoch 7/100\n",
      "54688/54688 [==============================] - 10s - loss: 3523461.1202 - val_loss: 3196833.6714\n",
      "Epoch 8/100\n",
      "54688/54688 [==============================] - 10s - loss: 3407781.4798 - val_loss: 3069442.7590\n",
      "Epoch 9/100\n",
      "54688/54688 [==============================] - 9s - loss: 3271869.8645 - val_loss: 2954956.6146\n",
      "Epoch 10/100\n",
      "54688/54688 [==============================] - 9s - loss: 3168993.9041 - val_loss: 2874389.0357\n",
      "Epoch 11/100\n",
      "54688/54688 [==============================] - 10s - loss: 3105044.5748 - val_loss: 2827273.4749\n",
      "Epoch 12/100\n",
      "54688/54688 [==============================] - 10s - loss: 3074181.8676 - val_loss: 2787499.6563\n",
      "Epoch 13/100\n",
      "54688/54688 [==============================] - 10s - loss: 3039842.6280 - val_loss: 2761749.2695\n",
      "Epoch 14/100\n",
      "54688/54688 [==============================] - 10s - loss: 3017614.4222 - val_loss: 2742492.5150\n",
      "Epoch 15/100\n",
      "54688/54688 [==============================] - 10s - loss: 2992720.1076 - val_loss: 2730917.3785\n",
      "Epoch 16/100\n",
      "54688/54688 [==============================] - 11s - loss: 2974230.8502 - val_loss: 2719079.5986\n",
      "Epoch 17/100\n",
      "54688/54688 [==============================] - 10s - loss: 2963049.7882 - val_loss: 2706896.4004\n",
      "Epoch 18/100\n",
      "54688/54688 [==============================] - 9s - loss: 2935733.8231 - val_loss: 2692369.0001\n",
      "Epoch 19/100\n",
      "54688/54688 [==============================] - 10s - loss: 2929843.2725 - val_loss: 2681127.9283\n",
      "Epoch 20/100\n",
      "54688/54688 [==============================] - 9s - loss: 2926613.0541 - val_loss: 2687226.0375\n",
      "Epoch 21/100\n",
      "54688/54688 [==============================] - 10s - loss: 2920899.5790 - val_loss: 2674614.9492\n",
      "Epoch 22/100\n",
      "54688/54688 [==============================] - 9s - loss: 2905011.2687 - val_loss: 2659354.1123\n",
      "Epoch 23/100\n",
      "54688/54688 [==============================] - 10s - loss: 2894960.7631 - val_loss: 2651467.7288\n",
      "Epoch 24/100\n",
      "54688/54688 [==============================] - 9s - loss: 2882012.4560 - val_loss: 2641817.9049\n",
      "Epoch 25/100\n",
      "54688/54688 [==============================] - 10s - loss: 2871802.7937 - val_loss: 2638155.3931\n",
      "Epoch 26/100\n",
      "54688/54688 [==============================] - 10s - loss: 2874101.0627 - val_loss: 2629979.2398\n",
      "Epoch 27/100\n",
      "54688/54688 [==============================] - 11s - loss: 2856721.0584 - val_loss: 2623793.1303\n",
      "Epoch 28/100\n",
      "54688/54688 [==============================] - 9s - loss: 2835491.2079 - val_loss: 2623573.7933\n",
      "Epoch 29/100\n",
      "54688/54688 [==============================] - 10s - loss: 2839175.1235 - val_loss: 2613351.1265\n",
      "Epoch 30/100\n",
      "54688/54688 [==============================] - 9s - loss: 2820692.2964 - val_loss: 2612306.9077\n",
      "Epoch 31/100\n",
      "54688/54688 [==============================] - 9s - loss: 2809894.1486 - val_loss: 2591482.5334\n",
      "Epoch 32/100\n",
      "54688/54688 [==============================] - 9s - loss: 2793710.4150 - val_loss: 2580097.9119\n",
      "Epoch 33/100\n",
      "54688/54688 [==============================] - 10s - loss: 2788628.8444 - val_loss: 2574799.8014\n",
      "Epoch 34/100\n",
      "54688/54688 [==============================] - 10s - loss: 2790640.5421 - val_loss: 2566142.3823\n",
      "Epoch 35/100\n",
      "54688/54688 [==============================] - 11s - loss: 2784587.5685 - val_loss: 2554464.7251\n",
      "Epoch 36/100\n",
      "54688/54688 [==============================] - 11s - loss: 2760110.8535 - val_loss: 2556180.5146\n",
      "Epoch 37/100\n",
      "54688/54688 [==============================] - 10s - loss: 2747844.5722 - val_loss: 2541199.6269\n",
      "Epoch 38/100\n",
      "54688/54688 [==============================] - 9s - loss: 2749238.5443 - val_loss: 2532620.3936\n",
      "Epoch 39/100\n",
      "54688/54688 [==============================] - 9s - loss: 2729145.8567 - val_loss: 2527424.1003\n",
      "Epoch 40/100\n",
      "54688/54688 [==============================] - 10s - loss: 2709825.7787 - val_loss: 2509003.6539\n",
      "Epoch 41/100\n",
      "54688/54688 [==============================] - 9s - loss: 2710464.1573 - val_loss: 2512274.3977\n",
      "Epoch 42/100\n",
      "54688/54688 [==============================] - 10s - loss: 2703459.9411 - val_loss: 2493834.4648\n",
      "Epoch 43/100\n",
      "54688/54688 [==============================] - 11s - loss: 2695679.9765 - val_loss: 2483654.7713\n",
      "Epoch 44/100\n",
      "54688/54688 [==============================] - 14s - loss: 2679138.7211 - val_loss: 2476041.9857\n",
      "Epoch 45/100\n",
      "54688/54688 [==============================] - 14s - loss: 2682048.2105 - val_loss: 2470247.0305\n",
      "Epoch 46/100\n",
      "54688/54688 [==============================] - 13s - loss: 2673898.5335 - val_loss: 2467612.6521\n",
      "Epoch 47/100\n",
      "54688/54688 [==============================] - 14s - loss: 2654514.8614 - val_loss: 2446411.6778\n",
      "Epoch 48/100\n",
      "54688/54688 [==============================] - 13s - loss: 2649763.1208 - val_loss: 2432338.4478\n",
      "Epoch 49/100\n",
      "54688/54688 [==============================] - 13s - loss: 2621477.1322 - val_loss: 2422604.2356\n",
      "Epoch 50/100\n",
      "54688/54688 [==============================] - 13s - loss: 2612036.2213 - val_loss: 2430891.9114\n",
      "Epoch 51/100\n",
      "54688/54688 [==============================] - 13s - loss: 2603596.5331 - val_loss: 2411167.0659\n",
      "Epoch 52/100\n",
      "54688/54688 [==============================] - 13s - loss: 2603695.9055 - val_loss: 2405746.9567\n",
      "Epoch 53/100\n",
      "54688/54688 [==============================] - 13s - loss: 2587341.5857 - val_loss: 2416595.8604\n",
      "Epoch 54/100\n",
      "54688/54688 [==============================] - 15s - loss: 2568609.7366 - val_loss: 2371124.8667\n",
      "Epoch 55/100\n",
      "54688/54688 [==============================] - 13s - loss: 2558561.2552 - val_loss: 2368380.5004\n",
      "Epoch 56/100\n",
      "54688/54688 [==============================] - 13s - loss: 2553227.9864 - val_loss: 2345872.7568\n",
      "Epoch 57/100\n",
      "54688/54688 [==============================] - 13s - loss: 2550092.3290 - val_loss: 2343637.9656\n",
      "Epoch 58/100\n",
      "54688/54688 [==============================] - 13s - loss: 2518973.1148 - val_loss: 2337728.3417\n",
      "Epoch 59/100\n",
      "54688/54688 [==============================] - 10s - loss: 2527978.9595 - val_loss: 2315281.7973\n",
      "Epoch 60/100\n",
      "54688/54688 [==============================] - 9s - loss: 2522554.5975 - val_loss: 2313120.5590\n",
      "Epoch 61/100\n",
      "54688/54688 [==============================] - 9s - loss: 2488796.8498 - val_loss: 2297811.9521\n",
      "Epoch 62/100\n",
      "54688/54688 [==============================] - 9s - loss: 2468450.8874 - val_loss: 2281822.6021\n",
      "Epoch 63/100\n",
      "54688/54688 [==============================] - 10s - loss: 2464832.0064 - val_loss: 2279990.5646\n",
      "Epoch 64/100\n",
      "54688/54688 [==============================] - 10s - loss: 2455383.3177 - val_loss: 2273851.9859\n",
      "Epoch 65/100\n",
      "54688/54688 [==============================] - 9s - loss: 2453351.7060 - val_loss: 2243803.6792\n",
      "Epoch 66/100\n",
      "54688/54688 [==============================] - 10s - loss: 2436312.5205 - val_loss: 2235465.5480\n",
      "Epoch 67/100\n",
      "54688/54688 [==============================] - 9s - loss: 2424261.4413 - val_loss: 2225002.9186\n",
      "Epoch 68/100\n",
      "54688/54688 [==============================] - 9s - loss: 2404443.1688 - val_loss: 2215659.2615\n",
      "Epoch 69/100\n",
      "54688/54688 [==============================] - 9s - loss: 2399797.8228 - val_loss: 2198661.4297\n",
      "Epoch 70/100\n",
      "54688/54688 [==============================] - 10s - loss: 2385612.0568 - val_loss: 2184033.6370\n",
      "Epoch 71/100\n",
      "54688/54688 [==============================] - 9s - loss: 2371069.6869 - val_loss: 2174051.0700\n",
      "Epoch 72/100\n",
      "54688/54688 [==============================] - 9s - loss: 2366452.6312 - val_loss: 2162437.6215\n",
      "Epoch 73/100\n",
      "54688/54688 [==============================] - 9s - loss: 2337595.7001 - val_loss: 2191520.5065\n",
      "Epoch 74/100\n",
      "54688/54688 [==============================] - 9s - loss: 2339700.8513 - val_loss: 2139394.2487\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54688/54688 [==============================] - 9s - loss: 2316124.3265 - val_loss: 2144031.2159\n",
      "Epoch 76/100\n",
      "54688/54688 [==============================] - 9s - loss: 2295813.5430 - val_loss: 2119007.1921\n",
      "Epoch 77/100\n",
      "54688/54688 [==============================] - 9s - loss: 2292291.3433 - val_loss: 2109767.2984\n",
      "Epoch 78/100\n",
      "54688/54688 [==============================] - 9s - loss: 2286933.3132 - val_loss: 2079867.1253\n",
      "Epoch 79/100\n",
      "54688/54688 [==============================] - 10s - loss: 2268932.1372 - val_loss: 2068798.4534\n",
      "Epoch 80/100\n",
      "54688/54688 [==============================] - 9s - loss: 2255380.9768 - val_loss: 2053655.2448\n",
      "Epoch 81/100\n",
      "54688/54688 [==============================] - 9s - loss: 2245229.8950 - val_loss: 2049209.2613\n",
      "Epoch 82/100\n",
      "54688/54688 [==============================] - 9s - loss: 2227699.2322 - val_loss: 2042098.5858\n",
      "Epoch 83/100\n",
      "54688/54688 [==============================] - 10s - loss: 2218323.1966 - val_loss: 2020599.0099\n",
      "Epoch 84/100\n",
      "54688/54688 [==============================] - 10s - loss: 2195498.8990 - val_loss: 1992977.5037\n",
      "Epoch 85/100\n",
      "54688/54688 [==============================] - 10s - loss: 2175584.4335 - val_loss: 2008954.6711\n",
      "Epoch 86/100\n",
      "54688/54688 [==============================] - 9s - loss: 2172158.0332 - val_loss: 2020875.0603\n",
      "Epoch 87/100\n",
      "54688/54688 [==============================] - 9s - loss: 2147332.6863 - val_loss: 1975128.1419\n",
      "Epoch 88/100\n",
      "54688/54688 [==============================] - 9s - loss: 2135685.0888 - val_loss: 1939069.4375\n",
      "Epoch 89/100\n",
      "54688/54688 [==============================] - 9s - loss: 2116202.1025 - val_loss: 1944108.8773\n",
      "Epoch 90/100\n",
      "54688/54688 [==============================] - 9s - loss: 2105146.8174 - val_loss: 1926342.2090\n",
      "Epoch 91/100\n",
      "54688/54688 [==============================] - 9s - loss: 2070823.5741 - val_loss: 1891125.0502\n",
      "Epoch 92/100\n",
      "54688/54688 [==============================] - 9s - loss: 2076126.4847 - val_loss: 1887187.4236\n",
      "Epoch 93/100\n",
      "54688/54688 [==============================] - 9s - loss: 2053370.2671 - val_loss: 1886543.2328\n",
      "Epoch 94/100\n",
      "54688/54688 [==============================] - 9s - loss: 2026970.3418 - val_loss: 1847537.4336\n",
      "Epoch 95/100\n",
      "54688/54688 [==============================] - 9s - loss: 2013777.3356 - val_loss: 1849130.5317\n",
      "Epoch 96/100\n",
      "54688/54688 [==============================] - 10s - loss: 1992381.8086 - val_loss: 1813693.0162\n",
      "Epoch 97/100\n",
      "54688/54688 [==============================] - 14s - loss: 1968930.5378 - val_loss: 1795363.6217\n",
      "Epoch 98/100\n",
      "54688/54688 [==============================] - 14s - loss: 1971964.8580 - val_loss: 1794143.1994\n",
      "Epoch 99/100\n",
      "54688/54688 [==============================] - 15s - loss: 1960235.7732 - val_loss: 1766338.6702\n",
      "Epoch 100/100\n",
      "54688/54688 [==============================] - 13s - loss: 1930790.9088 - val_loss: 1762604.6998\n"
     ]
    }
   ],
   "source": [
    "out_dims = [1100]\n",
    "bss = [2000]\n",
    "num_epochs = 100\n",
    "dropout = 0.2\n",
    "verb = 1\n",
    "for out_dim in out_dims:\n",
    "    for bs in bss:\n",
    "        model = Sequential()\n",
    "        model.add(Dense(output_dim=out_dim, input_dim=X_train.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "        model.add(Dropout(dropout))\n",
    "#         model.add(Dense(output_dim=20,kernel_initializer='normal'))\n",
    "        model.add(Dense(output_dim=1, kernel_initializer='normal'))\n",
    "        model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "        \n",
    "        start = time.time()\n",
    "        model.fit(X, y, \n",
    "        verbose=verb, \n",
    "        nb_epoch=num_epochs, \n",
    "        batch_size=bs,\n",
    "        validation_data=(X_validation, y_validation))\n",
    "        end = time.time()\n",
    "        \n",
    "#         pred = model.predict(X_validation)\n",
    "#         accuracy = rmspe(y_validation, pred)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------//---------\n",
      "output      1100\n",
      "batch size  2000\n",
      "epochs  100\n",
      "RMSPE is  0.1136839385038404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nic = pd.read_csv('nic_submission.csv')\n",
    "nic_pred = nic.Sales\n",
    "\n",
    "pred_test = model.predict(X_test)\n",
    "\n",
    "for i in range (X_test.shape[0]) :\n",
    "    if df_test_store['Customers'].iloc[i] == 0 :\n",
    "        pred_test[i] = 0\n",
    "        \n",
    "accuracy = rmspe(nic_pred, pred_test)\n",
    "\n",
    "print('---------//---------')\n",
    "print('output     ',out_dim)\n",
    "print('batch size ',bs)\n",
    "print('epochs ',num_epochs)\n",
    "# print('time taken ',end-start)\n",
    "print(\"RMSPE is \",accuracy)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_test = model.predict(X_test)\n",
    "pred_test = np.reshape(pred_test, pred_test.shape[0])\n",
    "submission = pd.DataFrame()\n",
    "submission['Sales'] = pred_test\n",
    "cols = ['Id','Sales']\n",
    "submission['Id'] = submission.index + 1\n",
    "submission = submission[cols]\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
